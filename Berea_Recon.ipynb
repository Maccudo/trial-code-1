{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Berea Recon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PuHhV1J1iYDCnnzEh4MXaKJA2odFN4mU",
      "authorship_tag": "ABX9TyN0Id5EMzDkQjWRjNW4u2G4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maccudo/trial-code-1/blob/master/Berea_Recon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xVhB9trNjqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33aa5ba9-7b9e-4ff7-edfd-cc7f3cd98e9c"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f59af47f690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAceREWiNxBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root directory for dataset\n",
        "dataroot = \"drive/My Drive/celeba\"\n",
        "#DATA_PATH = '~/Data/mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 4\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IOYFkbDOOB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))\n",
        "                           ]))\n",
        "\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpWf9T6ESFhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy6YQmJCQzwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "e91d88ea-2930-4bf2-be1a-b4e1c7e1acd3"
      },
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:1], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f59a1792278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOlMlTm64MM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzumY03ARGDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxEslDnQRVDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49P0TltRbtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "029707ff-c505-4627-ef39-a6e2784247f3"
      },
      "source": [
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0ZwgFFReVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntFIWf43RoPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2a529ff2-baee-46c1-c6b5-05eece1fdbc2"
      },
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf35Uc24RqR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oaUMokwRzyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "ba94be23-2219-4a2e-a2f6-2a76003493c0"
      },
      "source": [
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d63ad1af2d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Forward pass real batch through D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Calculate loss on all-real batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-e0ec361ecf78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 4, 4], expected input[64, 3, 64, 64] to have 1 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBJ9Al0ySW97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "46086714-97d2-4b46-d326-015405282491"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYqmRutnSeD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "a4792e56-821c-40f3-fb15-91cd94f3b592"
      },
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\"\n",
              "href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/\n",
              "css/font-awesome.min.css\">\n",
              "<script language=\"javascript\">\n",
              "  function isInternetExplorer() {\n",
              "    ua = navigator.userAgent;\n",
              "    /* MSIE used to detect old browsers and Trident used to newer ones*/\n",
              "    return ua.indexOf(\"MSIE \") > -1 || ua.indexOf(\"Trident/\") > -1;\n",
              "  }\n",
              "\n",
              "  /* Define the Animation class */\n",
              "  function Animation(frames, img_id, slider_id, interval, loop_select_id){\n",
              "    this.img_id = img_id;\n",
              "    this.slider_id = slider_id;\n",
              "    this.loop_select_id = loop_select_id;\n",
              "    this.interval = interval;\n",
              "    this.current_frame = 0;\n",
              "    this.direction = 0;\n",
              "    this.timer = null;\n",
              "    this.frames = new Array(frames.length);\n",
              "\n",
              "    for (var i=0; i<frames.length; i++)\n",
              "    {\n",
              "     this.frames[i] = new Image();\n",
              "     this.frames[i].src = frames[i];\n",
              "    }\n",
              "    var slider = document.getElementById(this.slider_id);\n",
              "    slider.max = this.frames.length - 1;\n",
              "    if (isInternetExplorer()) {\n",
              "        // switch from oninput to onchange because IE <= 11 does not conform\n",
              "        // with W3C specification. It ignores oninput and onchange behaves\n",
              "        // like oninput. In contrast, Mircosoft Edge behaves correctly.\n",
              "        slider.setAttribute('onchange', slider.getAttribute('oninput'));\n",
              "        slider.setAttribute('oninput', null);\n",
              "    }\n",
              "    this.set_frame(this.current_frame);\n",
              "  }\n",
              "\n",
              "  Animation.prototype.get_loop_state = function(){\n",
              "    var button_group = document[this.loop_select_id].state;\n",
              "    for (var i = 0; i < button_group.length; i++) {\n",
              "        var button = button_group[i];\n",
              "        if (button.checked) {\n",
              "            return button.value;\n",
              "        }\n",
              "    }\n",
              "    return undefined;\n",
              "  }\n",
              "\n",
              "  Animation.prototype.set_frame = function(frame){\n",
              "    this.current_frame = frame;\n",
              "    document.getElementById(this.img_id).src =\n",
              "            this.frames[this.current_frame].src;\n",
              "    document.getElementById(this.slider_id).value = this.current_frame;\n",
              "  }\n",
              "\n",
              "  Animation.prototype.next_frame = function()\n",
              "  {\n",
              "    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));\n",
              "  }\n",
              "\n",
              "  Animation.prototype.previous_frame = function()\n",
              "  {\n",
              "    this.set_frame(Math.max(0, this.current_frame - 1));\n",
              "  }\n",
              "\n",
              "  Animation.prototype.first_frame = function()\n",
              "  {\n",
              "    this.set_frame(0);\n",
              "  }\n",
              "\n",
              "  Animation.prototype.last_frame = function()\n",
              "  {\n",
              "    this.set_frame(this.frames.length - 1);\n",
              "  }\n",
              "\n",
              "  Animation.prototype.slower = function()\n",
              "  {\n",
              "    this.interval /= 0.7;\n",
              "    if(this.direction > 0){this.play_animation();}\n",
              "    else if(this.direction < 0){this.reverse_animation();}\n",
              "  }\n",
              "\n",
              "  Animation.prototype.faster = function()\n",
              "  {\n",
              "    this.interval *= 0.7;\n",
              "    if(this.direction > 0){this.play_animation();}\n",
              "    else if(this.direction < 0){this.reverse_animation();}\n",
              "  }\n",
              "\n",
              "  Animation.prototype.anim_step_forward = function()\n",
              "  {\n",
              "    this.current_frame += 1;\n",
              "    if(this.current_frame < this.frames.length){\n",
              "      this.set_frame(this.current_frame);\n",
              "    }else{\n",
              "      var loop_state = this.get_loop_state();\n",
              "      if(loop_state == \"loop\"){\n",
              "        this.first_frame();\n",
              "      }else if(loop_state == \"reflect\"){\n",
              "        this.last_frame();\n",
              "        this.reverse_animation();\n",
              "      }else{\n",
              "        this.pause_animation();\n",
              "        this.last_frame();\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "\n",
              "  Animation.prototype.anim_step_reverse = function()\n",
              "  {\n",
              "    this.current_frame -= 1;\n",
              "    if(this.current_frame >= 0){\n",
              "      this.set_frame(this.current_frame);\n",
              "    }else{\n",
              "      var loop_state = this.get_loop_state();\n",
              "      if(loop_state == \"loop\"){\n",
              "        this.last_frame();\n",
              "      }else if(loop_state == \"reflect\"){\n",
              "        this.first_frame();\n",
              "        this.play_animation();\n",
              "      }else{\n",
              "        this.pause_animation();\n",
              "        this.first_frame();\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "\n",
              "  Animation.prototype.pause_animation = function()\n",
              "  {\n",
              "    this.direction = 0;\n",
              "    if (this.timer){\n",
              "      clearInterval(this.timer);\n",
              "      this.timer = null;\n",
              "    }\n",
              "  }\n",
              "\n",
              "  Animation.prototype.play_animation = function()\n",
              "  {\n",
              "    this.pause_animation();\n",
              "    this.direction = 1;\n",
              "    var t = this;\n",
              "    if (!this.timer) this.timer = setInterval(function() {\n",
              "        t.anim_step_forward();\n",
              "    }, this.interval);\n",
              "  }\n",
              "\n",
              "  Animation.prototype.reverse_animation = function()\n",
              "  {\n",
              "    this.pause_animation();\n",
              "    this.direction = -1;\n",
              "    var t = this;\n",
              "    if (!this.timer) this.timer = setInterval(function() {\n",
              "        t.anim_step_reverse();\n",
              "    }, this.interval);\n",
              "  }\n",
              "</script>\n",
              "\n",
              "<style>\n",
              ".animation {\n",
              "    display: inline-block;\n",
              "    text-align: center;\n",
              "}\n",
              "input[type=range].anim-slider {\n",
              "    width: 374px;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "}\n",
              ".anim-buttons {\n",
              "    margin: 8px 0px;\n",
              "}\n",
              ".anim-buttons button {\n",
              "    padding: 0;\n",
              "    width: 36px;\n",
              "}\n",
              ".anim-state label {\n",
              "    margin-right: 8px;\n",
              "}\n",
              ".anim-state input {\n",
              "    margin: 0;\n",
              "    vertical-align: middle;\n",
              "}\n",
              "</style>\n",
              "\n",
              "<div class=\"animation\">\n",
              "  <img id=\"_anim_img10e6ae9c45b248f19bae27d6b452500c\">\n",
              "  <div class=\"anim-controls\">\n",
              "    <input id=\"_anim_slider10e6ae9c45b248f19bae27d6b452500c\" type=\"range\" class=\"anim-slider\"\n",
              "           name=\"points\" min=\"0\" max=\"1\" step=\"1\" value=\"0\"\n",
              "           oninput=\"anim10e6ae9c45b248f19bae27d6b452500c.set_frame(parseInt(this.value));\"></input>\n",
              "    <div class=\"anim-buttons\">\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.slower()\"><i class=\"fa fa-minus\"></i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.first_frame()\"><i class=\"fa fa-fast-backward\">\n",
              "          </i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.previous_frame()\">\n",
              "          <i class=\"fa fa-step-backward\"></i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.reverse_animation()\">\n",
              "          <i class=\"fa fa-play fa-flip-horizontal\"></i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.pause_animation()\"><i class=\"fa fa-pause\">\n",
              "          </i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.play_animation()\"><i class=\"fa fa-play\"></i>\n",
              "          </button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.next_frame()\"><i class=\"fa fa-step-forward\">\n",
              "          </i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.last_frame()\"><i class=\"fa fa-fast-forward\">\n",
              "          </i></button>\n",
              "      <button onclick=\"anim10e6ae9c45b248f19bae27d6b452500c.faster()\"><i class=\"fa fa-plus\"></i></button>\n",
              "    </div>\n",
              "    <form action=\"#n\" name=\"_anim_loop_select10e6ae9c45b248f19bae27d6b452500c\" class=\"anim-state\">\n",
              "      <input type=\"radio\" name=\"state\" value=\"once\" id=\"_anim_radio1_10e6ae9c45b248f19bae27d6b452500c\"\n",
              "             >\n",
              "      <label for=\"_anim_radio1_10e6ae9c45b248f19bae27d6b452500c\">Once</label>\n",
              "      <input type=\"radio\" name=\"state\" value=\"loop\" id=\"_anim_radio2_10e6ae9c45b248f19bae27d6b452500c\"\n",
              "             checked>\n",
              "      <label for=\"_anim_radio2_10e6ae9c45b248f19bae27d6b452500c\">Loop</label>\n",
              "      <input type=\"radio\" name=\"state\" value=\"reflect\" id=\"_anim_radio3_10e6ae9c45b248f19bae27d6b452500c\"\n",
              "             >\n",
              "      <label for=\"_anim_radio3_10e6ae9c45b248f19bae27d6b452500c\">Reflect</label>\n",
              "    </form>\n",
              "  </div>\n",
              "</div>\n",
              "\n",
              "\n",
              "<script language=\"javascript\">\n",
              "  /* Instantiate the Animation class. */\n",
              "  /* The IDs given should match those used in the template above. */\n",
              "  (function() {\n",
              "    var img_id = \"_anim_img10e6ae9c45b248f19bae27d6b452500c\";\n",
              "    var slider_id = \"_anim_slider10e6ae9c45b248f19bae27d6b452500c\";\n",
              "    var loop_select_id = \"_anim_loop_select10e6ae9c45b248f19bae27d6b452500c\";\n",
              "    var frames = new Array(0);\n",
              "    \n",
              "\n",
              "\n",
              "    /* set a timeout to make sure all the above elements are created before\n",
              "       the object is initialized. */\n",
              "    setTimeout(function() {\n",
              "        anim10e6ae9c45b248f19bae27d6b452500c = new Animation(frames, img_id, slider_id, 1000.0,\n",
              "                                 loop_select_id);\n",
              "    }, 0);\n",
              "  })()\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAHBCAYAAADkRYtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAGtElEQVR4nO3VwQ3AIBDAsNL9dz42QPkhJHuC/LJm5gMAzv7bAQDwAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAIDBMAAsMEgMAwASAwTAAINlf1Bn//RKHCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQ-LrQVSroM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6e46586-49fc-442d-ac63-36f54691a2a4"
      },
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-90391afba428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fake Images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}